{"cells":[{"cell_type":"code","source":["from sklearn import metrics\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split, cross_val_predict, GridSearchCV"],"metadata":{"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# RESULTADOS\ndef resultados(labelsTeste, predicoes):\n    acc = metrics.accuracy_score(labelsTeste, predicoes)\n    fscore = metrics.f1_score(labelsTeste, predicoes, average='macro')\n    prec = metrics.precision_score(labelsTeste, predicoes, average='macro')\n    recall = metrics.recall_score(labelsTeste, predicoes, average='macro')\n    return [acc, fscore, prec, recall]"],"metadata":{"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":["import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from keras.utils import to_categorical\noriginal_train = pd.read_csv('/kaggle/input/titanic/train.csv')\noriginal_test = pd.read_csv('/kaggle/input/titanic/test.csv')\nlabel_test = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')"],"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":["label_train = original_train[['PassengerId','Survived']]\ndata_train = original_train.drop(['Survived'], axis=1)\n\ndata_test = original_test\n\ndata_train"],"metadata":{"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Verifica quantidade de NaN values por coluna\ndata_train.isna().sum()"],"metadata":{"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# Verifica quantidade de NaN values por coluna\ndata_test.isna().sum()"],"metadata":{"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# Mining PCLASS\nclass_train = pd.get_dummies(data_train['Pclass'], prefix='class', drop_first=True)\ndata_train = pd.concat([data_train,class_train], axis=1).drop(['Pclass'], axis=1)\n\nclass_test = pd.get_dummies(data_test['Pclass'], prefix='class', drop_first=True)\ndata_test = pd.concat([data_test,class_test], axis=1).drop(['Pclass'], axis=1)\n\ndata_train"],"metadata":{"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# Mining SEX\nsex_train = pd.get_dummies(data_train['Sex'], prefix='sex', drop_first=True)\ndata_train = pd.concat([data_train,sex_train], axis=1).drop(['Sex'], axis=1)\n\nsex_test = pd.get_dummies(data_test['Sex'], prefix='sex', drop_first=True)\ndata_test = pd.concat([data_test,sex_test], axis=1).drop(['Sex'], axis=1)\n\ndata_train"],"metadata":{"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":["data_train['FamilySize'] = data_train['SibSp'] + data_train['Parch'] + 1\n\n# Miningn SIBSP and PARCH\ndata_train['FamilySize'] = np.where(data_train['FamilySize'] > 4, 'Big',\\\n                                 np.where(data_train['FamilySize'] > 1, 'Small', 'Single'))\nfamily_train = pd.get_dummies(data_train['FamilySize'], prefix='FamilySize', drop_first=True)\ndata_train = pd.concat([data_train,family_train], axis=1).drop(['FamilySize','SibSp','Parch'], axis=1)\n\n\ndata_test['FamilySize'] = data_test['SibSp'] + data_test['Parch'] + 1\ndata_test['FamilySize'] = np.where(data_test['FamilySize'] > 4, 'Big',\\\n                                 np.where(data_test['FamilySize'] > 1, 'Small', 'Single'))\nfamily_test = pd.get_dummies(data_test['FamilySize'], prefix='FamilySize', drop_first=True)\ndata_test = pd.concat([data_test,family_test], axis=1).drop(['FamilySize','SibSp','Parch'], axis=1)\n\ndata_train"],"metadata":{"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# Fill Embarked nan-values with MODE\ndata_train['Embarked'] = data_train['Embarked'].fillna('S')"],"metadata":{"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# Mining EMBARKED\nembark_train = pd.get_dummies(data_train['Embarked'], prefix='embark', drop_first=True)\ndata_train = pd.concat([data_train,embark_train], axis=1).drop(['Embarked'], axis=1)\n\nembark_test = pd.get_dummies(data_test['Embarked'], prefix='embark', drop_first=True)\ndata_test = pd.concat([data_test,embark_test], axis=1).drop(['Embarked'], axis=1)\n\ndata_train"],"metadata":{"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":["data_train.isna().sum()"],"metadata":{"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# Minerando Fare para base de treino\ndata_train['FareMean'] = np.array(np.floor(np.array(data_train['Fare']) / 10.))\ndata_train = data_train.drop(['Fare'], axis=1)\n\n# Minerando Fare para base de treino\ndata_test['FareMean'] = np.array(np.floor(np.array(data_test['Fare']) / 10.))\ndata_test['FareMean'] = data_test['FareMean'].fillna(data_test['FareMean'].median())\ndata_test = data_test.drop(['Fare'], axis=1)\n\ndata_train"],"metadata":{"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# Minerando Name para base de treino\ndata_train['NameTitle'] = data_train['Name'].astype(str).str.split(',').str[1] # get title with space and dot\ndata_train['NameTitle'] = data_train['NameTitle'].astype(str).str.split('.').str[0] # get title with space\ndata_train['NameTitle'] = data_train['NameTitle'].astype(str).str[1:] # get title only\ndata_train['NameTitle'] = data_train['NameTitle'].replace(['Don','Dona','Rev','Dr','Mme','Ms','Major','Lady','Sir','Mlle','Col','Capt','the Countess','Jonkheer'], 'Others')\ndata_train = data_train.drop(['Name'], axis=1)\n\n# Minerando Name para base de teste\ndata_test['NameTitle'] = data_test['Name'].astype(str).str.split(',').str[1]\ndata_test['NameTitle'] = data_test['NameTitle'].astype(str).str.split('.').str[0] # get title with space\ndata_test['NameTitle'] = data_test['NameTitle'].astype(str).str[1:] # get title only\ndata_test['NameTitle'] = data_test['NameTitle'].replace(['an','Don','Dona','Rev','Dr','Mme','Ms','Major','Lady','Sir','Mlle','Col','Capt','the Countess','Jonkheer'], 'Others')\ndata_test = data_test.drop(['Name'], axis=1)\n\ndata_train"],"metadata":{"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":["data_test.NameTitle.unique()"],"metadata":{"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# Mining NAMETITLE\ntitle_train = pd.get_dummies(data_train['NameTitle'], prefix='title', drop_first=True)\ndata_train = pd.concat([data_train,title_train], axis=1).drop(['NameTitle'], axis=1)\n\ntitle_test = pd.get_dummies(data_test['NameTitle'], prefix='title', drop_first=True)\ndata_test = pd.concat([data_test,title_test], axis=1).drop(['NameTitle'], axis=1)\n\ndata_train"],"metadata":{"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# Mining AGE\ndata_train['Age'] = data_train['Age'].fillna(data_train['Age'].median())\n\ndata_test['Age'] = data_test['Age'].fillna(data_test['Age'].median())\n\ndata_train"],"metadata":{"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# Dropping PASSENGERID, TICKET and CABIN (cabin too much missing values)\n\ndata_train = data_train.drop(['PassengerId','Ticket','Cabin'], axis=1)\n\ndata_test = data_test.drop(['PassengerId','Ticket','Cabin'], axis=1)\n\ndata_train"],"metadata":{"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":["data_train.isna().sum()"],"metadata":{"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":["data_test.isna().sum()"],"metadata":{"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":["data_train.dtypes.sample(len(data_train.columns))"],"metadata":{"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# List of features for later use\nfeature_list = list(data_train.columns)\nfeature_list"],"metadata":{"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#Separar os dados dos labels\n\ntrain_X = np.array(data_train) #train data\ntrain_Y = np.array(label_train.iloc[:, 1]) #train labels\n\ntest_X = np.array(data_test) #test data\ntest_Y = np.array(label_test.iloc[:, 1]) #test labels"],"metadata":{"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":["print('Training data shape : ', train_X.shape, train_Y.shape)\nprint('Testing data shape : ', test_X.shape, test_Y.shape)"],"metadata":{"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":["# Verify Nan Values in an array\nnp.isnan(sum(train_X))"],"metadata":{"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":["# Verify Nan Values in an array\nnp.isnan(sum(test_X))"],"metadata":{"trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":["# Encontrar o n√∫mero de classes existentes no conjunto de treino\nclasses = np.unique(train_Y)\nnClasses = len(classes)\nprint('Total number of outputs : ', nClasses)\nprint('Output classes : ', classes)"],"metadata":{"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":["#IMPORTANDO SKLEARN E SEPARANDO TREINO/TESTE PARA O MODELO\n\ndataNoLabels = train_X\nlabels = train_Y\n\ntrain_data,valid_data,train_label,valid_label = train_test_split(dataNoLabels, labels, test_size=0.1, random_state=13)\n\nnp.size(labels)"],"metadata":{"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":["# Param Grid for SVC\nparam_grid = { \n    'kernel': ['rbf', 'linear'],\n    'C' : [1,10,100,1000],\n    'gamma' :[1, 1e-1, 1e-3, 1e-4]\n}\nclf = SVC()"],"metadata":{"trusted":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":["#CV_clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv= 3) # search with CV\n#CV_clf = GridSearchCV(estimator=clf, param_grid=param_grid, refit = True, verbose=2) # search without CV\n#CV_clf.fit(train_data, np.ravel(train_label,order='C'))\n#CV_clf.best_params_"],"metadata":{"trusted":true},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# Treina e valida o modelo\nclf = SVC(C=10000, gamma=0.0001, kernel='rbf').fit(train_data, np.ravel(train_label,order='C')) #train SVC\n\npredicoes = cross_val_predict(clf, valid_data, valid_label, cv=5)\n\nacc, f1s, precisao, recall = resultados(valid_label, predicoes) #show results\nprint(\"\\nEVALUATION METRICS\\n\"\n        \"acc: %0.4f - fscore: %0.4f - prec: %0.4f - recall: %0.4f\\n\" % (acc, f1s, precisao, recall))"],"metadata":{"trusted":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":["# --------- TESTE --------- #"],"metadata":{"trusted":true},"outputs":[],"execution_count":33},{"cell_type":"code","source":["predicoes_teste = clf.predict(test_X) # Original Classifier and Original test data\n\nacc, f1s, precisao, recall = resultados(test_Y, predicoes_teste) #show results\nprint(\"\\nEVALUATION METRICS\\n\"\n        \"acc: %0.4f - fscore: %0.4f - prec: %0.4f - recall: %0.4f\\n\" % (acc, f1s, precisao, recall))"],"metadata":{"trusted":true},"outputs":[],"execution_count":34},{"cell_type":"code","source":["df_pass = pd.DataFrame(original_test['PassengerId'])\ndf_pred = pd.DataFrame(predicoes_teste, columns=['Survived'])\ndf_result = pd.concat([df_pass['PassengerId'], df_pred['Survived']], axis=1, keys=['PassengerId', 'Survived'])\ndf_result"],"metadata":{"trusted":true},"outputs":[],"execution_count":35},{"cell_type":"code","source":["df_result.to_csv('titanic.csv',index=False)"],"metadata":{"trusted":true},"outputs":[],"execution_count":36}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.4","nbconvert_exporter":"python","file_extension":".py"},"name":"titanic-surviving-predictor","notebookId":1085516307990090},"nbformat":4,"nbformat_minor":0}
